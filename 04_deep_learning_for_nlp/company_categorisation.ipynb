{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40ad3c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "description",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e65cf8de-2aee-4800-bcf7-57444e8f14a7",
       "rows": [
        [
         "0",
         "Animals & Pets",
         "ruffandtumbledogcoats.com",
         "At Ruff and Tumble we are proud to be the market leaders in Dog Drying Coats.\n\nOur high-quality, super-absorbent, double thickness soft cotton towelling drying rugs, with their unique, practical yet stylish design, is what sets us apart from other brands. Everything we make at Ruff and Tumble is designed with dogs and their owners in mind. Our Dog Drying Robes, Mitts, Bed Covers and Sofa Throws are the ultimate solution for managing wet dogs. Designed with care, and made from top quality cotton towelling, the Ruff and Tumble range is simply essential for dog owners everywhere."
        ],
        [
         "1",
         "Animals & Pets",
         "protect-mypet.com",
         "A truly tailored solution to parasite protection\n\nOur goal is simple: to keep every pet protected from parasites, by making parasite protection as easy and accessible as possible.\n\nWe deliver flea, tick and worm treatments through your letterbox in exactly the right doses for your pet, at exactly the right time. Simply answer a few questions about your pet, and select from a range of treatment options. We’ll tailor their treatments and put everything in their very own personalised dispensing envelope. When it arrives in the post, it’s time to dose! You’ll never forget to protect, and you can enjoy the convenience of having your pet’s care on your doormat when you need it.\n\nVet-recommended treatments you can trust\n\nOur protection options include the UK’s No. 1 flea treatment, Frontline Plus, as well as market-leaders, Drontal and Dronspot, and other reputable products that are safe, effective and provide long-lasting protection. As a team of veterinary professionals ourselves, we wouldn’t have it any other way.\n\nA commitment-free subscription that you control\n\nEverything you need to manage your subscription is available at your fingertips via your online account. Make changes to your pet’s protection, add other pets to your subscription, pause or cancel deliveries and more.\n\nWant to know more?\n\n\nVisit our website to read our story, discover how we’re supporting pet welfare charities and enjoy fun reads in our pet-friendly hub: www.protect-mypet.com\n"
        ],
        [
         "2",
         "Animals & Pets",
         "vetscriptions.co.uk",
         "We care about your pets and believe that they should have access to the right medicines at an affordable price. We only sell products that your Vet would recommend so you can trust that our products are reliable and most importantly safe for your pet.\n\nWe can supply exactly the same products, from exactly the same suppliers as your local veterinary clinic, but because we are an online only retailer our overheads are lower, we can keep our prices lower too. In fact we guarantee that you will save at least 40% every time you buy from us\n\nWe sell prescription and other veterinary medicines, health supplements, nutraceuticals, remedies, animal medications online... basically all the health products that you might ever need, at HUGE discounts! \n\n"
        ],
        [
         "3",
         "Animals & Pets",
         "animal-health.co.uk",
         "With market leading products, numerous awards and an impressive amount of media coverage, The Animal Health Company remains at the very forefront of animal care. The Animal Health Company produce a leading range of complementary feeds for equines and canines. The company was originally formed in 1990 and since then, has continued to make outstanding contributions to the world of animal healthcare. The meticulous research carried out by the Animal Health Company strongly reflects that of their motto, “committed to animal care.”"
        ],
        [
         "4",
         "Animals & Pets",
         "www.travellingpet.vet",
         "I am a veterinary surgeon qualified to complete paperwork for pet travel to the E.U. and further afield. I offer a home visit service and a hassle free way to get your paperwork completed before travel."
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animals &amp; Pets</td>\n",
       "      <td>ruffandtumbledogcoats.com</td>\n",
       "      <td>At Ruff and Tumble we are proud to be the mark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animals &amp; Pets</td>\n",
       "      <td>protect-mypet.com</td>\n",
       "      <td>A truly tailored solution to parasite protecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animals &amp; Pets</td>\n",
       "      <td>vetscriptions.co.uk</td>\n",
       "      <td>We care about your pets and believe that they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animals &amp; Pets</td>\n",
       "      <td>animal-health.co.uk</td>\n",
       "      <td>With market leading products, numerous awards ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animals &amp; Pets</td>\n",
       "      <td>www.travellingpet.vet</td>\n",
       "      <td>I am a veterinary surgeon qualified to complet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                    company  \\\n",
       "0  Animals & Pets  ruffandtumbledogcoats.com   \n",
       "1  Animals & Pets          protect-mypet.com   \n",
       "2  Animals & Pets        vetscriptions.co.uk   \n",
       "3  Animals & Pets        animal-health.co.uk   \n",
       "4  Animals & Pets      www.travellingpet.vet   \n",
       "\n",
       "                                         description  \n",
       "0  At Ruff and Tumble we are proud to be the mark...  \n",
       "1  A truly tailored solution to parasite protecti...  \n",
       "2  We care about your pets and believe that they ...  \n",
       "3  With market leading products, numerous awards ...  \n",
       "4  I am a veterinary surgeon qualified to complet...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/trustpilot_company_descriptions.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5f82cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1680"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ff03fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Restaurants & Bars              0.059524\n",
       "Food, Beverages & Tobacco       0.055357\n",
       "Business Services               0.052976\n",
       "Sports                          0.051786\n",
       "Education & Training            0.051190\n",
       "Hobbies & Crafts                0.050000\n",
       "Home Services                   0.049405\n",
       "Animals & Pets                  0.049405\n",
       "Public & Local Services         0.047619\n",
       "Legal Services & Government     0.046429\n",
       "Events & Entertainment          0.045238\n",
       "Home & Garden                   0.045238\n",
       "Health & Medical                0.045238\n",
       "Beauty & Well-being             0.042857\n",
       "Money & Insurance               0.041667\n",
       "Electronics & Technology        0.041071\n",
       "Utilities                       0.040476\n",
       "Shopping & Fashion              0.039881\n",
       "Construction & Manufacturing    0.039881\n",
       "Vehicles & Transportation       0.035714\n",
       "Media & Publishing              0.035119\n",
       "Travel & Vacation               0.033929\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78e4d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# https://research.google/blog/a-fast-wordpiece-tokenization-system/\n",
    "from tokenizers import Tokenizer\n",
    "tokenizer = Tokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "def wordpiece_tokenize(text, max_length=128, truncation=True):\n",
    "\t\n",
    "\t# Tokenize the text using WordPiece\n",
    "\t# https://huggingface.co/docs/tokenizers/quicktour\n",
    "\tall_ids = tokenizer.encode(text).ids\n",
    "\n",
    "\tif len(all_ids) > max_length and truncation:\n",
    "\t\tall_ids = all_ids[:max_length]\n",
    "\t# Pad the sequence to max_length\n",
    "\tif len(all_ids) < max_length:\n",
    "\t\tall_ids += [0] * (max_length - len(all_ids))\n",
    "\t# Convert to tensor\n",
    "\tall_ids = torch.tensor(all_ids, dtype=torch.long)\n",
    "\n",
    "\treturn {\n",
    "\t\t'input_ids': all_ids,\n",
    "\t}\n",
    "\n",
    "# Encode categories\n",
    "df['category_encoded'] = label_encoder.fit_transform(df['category'])\n",
    "\n",
    "# Tokenize descriptions\n",
    "class TextDataset(Dataset):\n",
    "\tdef __init__(self, descriptions, labels, tokenizer, max_len=128):\n",
    "\t\tself.descriptions = descriptions\n",
    "\t\tself.labels = labels\n",
    "\t\tself.tokenizer = tokenizer\n",
    "\t\tself.max_len = max_len\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.descriptions)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\ttext = self.descriptions[idx]\n",
    "\t\tlabel = self.labels[idx]\n",
    "\t\tencoding = self.tokenizer(\n",
    "\t\t\ttext,\n",
    "\t\t\tmax_length=self.max_len,\n",
    "\t\t)\n",
    "\t\treturn {\n",
    "\t\t\t'input_ids': encoding['input_ids'].squeeze(0),\n",
    "\t\t\t'label': torch.tensor(label, dtype=torch.long)\n",
    "\t\t}\n",
    "\n",
    "# sample initially for dev: df = df.sample(frac=0.1, random_state=42)\n",
    "descriptions = df['description'].tolist()\n",
    "labels = df['category_encoded'].tolist()\n",
    "\n",
    "# TODO: make this a 3 split (train, val, test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(descriptions, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "\n",
    "train_dataset = TextDataset(X_train, y_train, wordpiece_tokenize)\n",
    "test_dataset = TextDataset(X_test, y_test, wordpiece_tokenize)\n",
    "val_dataset = TextDataset(X_val, y_val, wordpiece_tokenize)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d97ab609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1075, 269, 336)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9d8f90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleLSTM(\n",
       "  (embedding): Embedding(30522, 128, padding_idx=0)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (lstm): LSTM(128, 128, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=22, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Define LSTM with Attention\n",
    "class SimpleLSTM(nn.Module):\n",
    "\tdef __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):\n",
    "\t\tsuper(SimpleLSTM, self).__init__()\n",
    "\t\tself.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "\t\tself.dropout = nn.Dropout(0.5)\n",
    "\t\tself.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "\t\tself.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "\t# TODO: \n",
    "\t# - update the forward pass to use the max/mean of all hidden states\n",
    "\t# - stack more LSTM layers, and use a bidirectional LSTM\n",
    "\tdef forward(self, input_ids):\n",
    "\t\tembedded = self.dropout(self.embedding(input_ids))\n",
    "\t\tlstm_out, _ = self.lstm(embedded)\n",
    "\t\toutput = self.fc(lstm_out[:,-1])\n",
    "\t\treturn output\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "# https://huggingface.co/google-bert/bert-base-uncased#preprocessing\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "embed_dim = 128\n",
    "hidden_dim = 128\n",
    "num_classes = len(label_encoder.classes_)\n",
    "epochs = 10\n",
    "\n",
    "model = SimpleLSTM(vocab_size, embed_dim, hidden_dim, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training Loop\n",
    "# later: use gpu for training by `device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')`\n",
    "device = torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd3ccaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:01<00:00, 21.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Accuracy: 0.05\n",
      "Epoch 1, Loss: 3.09342317721423\n",
      "Validation Accuracy: 0.04\n",
      "Validation loss 1, Loss: 3.089724726147122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:01<00:00, 22.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Accuracy: 0.08\n",
      "Epoch 2, Loss: 3.0649471212835873\n",
      "Validation Accuracy: 0.06\n",
      "Validation loss 2, Loss: 3.0877423021528454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:01<00:00, 24.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Accuracy: 0.13\n",
      "Epoch 3, Loss: 3.0345231084262623\n",
      "Validation Accuracy: 0.06\n",
      "Validation loss 3, Loss: 3.0872492525312634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:01<00:00, 23.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Accuracy: 0.15\n",
      "Epoch 4, Loss: 3.0026459343293133\n",
      "Validation Accuracy: 0.06\n",
      "Validation loss 4, Loss: 3.090924951765272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:01<00:00, 22.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Accuracy: 0.17\n",
      "Epoch 5, Loss: 2.953059427878436\n",
      "Validation Accuracy: 0.06\n",
      "Validation loss 5, Loss: 3.0984336270226374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:01<00:00, 19.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Accuracy: 0.18\n",
      "Epoch 6, Loss: 2.8977027500376984\n",
      "Validation Accuracy: 0.06\n",
      "Validation loss 6, Loss: 3.1286669042375355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:01<00:00, 20.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Accuracy: 0.21\n",
      "Epoch 7, Loss: 2.816315973506254\n",
      "Validation Accuracy: 0.05\n",
      "Validation loss 7, Loss: 3.1604720486534967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:01<00:00, 20.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Accuracy: 0.22\n",
      "Epoch 8, Loss: 2.7719617871677174\n",
      "Validation Accuracy: 0.06\n",
      "Validation loss 8, Loss: 3.1643274095323353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:01<00:00, 20.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Accuracy: 0.25\n",
      "Epoch 9, Loss: 2.687328247463002\n",
      "Validation Accuracy: 0.06\n",
      "Validation loss 9, Loss: 3.2188175784216986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:01<00:00, 19.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Accuracy: 0.26\n",
      "Epoch 10, Loss: 2.5997806296629062\n",
      "Validation Accuracy: 0.05\n",
      "Validation loss 10, Loss: 3.2428407933976917\n",
      "Test Accuracy: 0.08\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\tmodel.train()\n",
    "\ttotal_loss = 0\n",
    "\ttrain_correct = 0\n",
    "\tfor batch in tqdm(train_loader):\n",
    "\t\tinput_ids = batch['input_ids'].to(device)\n",
    "\t\tlabels = batch['label'].to(device)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs = model(input_ids)\n",
    "\t\tloss = criterion(outputs, labels)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\ttotal_loss += loss.item()\n",
    "\t\t_, predicted = torch.max(outputs, 1)\n",
    "\t\ttrain_correct += (predicted == labels).sum().item()\n",
    "\ttrain_accuracy = train_correct / len(train_loader.dataset)\n",
    "\tprint(f\"Epoch {epoch + 1}, Train Accuracy: {train_accuracy:.2f}\")\n",
    "\tprint(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "\t# TODO: validate the model after each epoch\n",
    "\tmodel.eval()\n",
    "\tcorrect = 0\n",
    "\ttotal = 0\n",
    "\tval_loss = 0\n",
    "\twith torch.no_grad():\n",
    "\t\tfor batch in val_loader:\n",
    "\t\t\tinput_ids = batch['input_ids'].to(device)\n",
    "\t\t\tlabels = batch['label'].to(device)\n",
    "\n",
    "\t\t\toutputs = model(input_ids)\n",
    "\t\t\tloss = criterion(outputs, labels)\n",
    "\t\t\tval_loss += loss.item()\n",
    "\n",
    "\t\t\t_, predicted = torch.max(outputs, 1)\n",
    "\t\t\ttotal += labels.size(0)\n",
    "\t\t\tcorrect += (predicted == labels).sum().item()\n",
    "\tprint(f\"Validation Accuracy: {correct / total:.2f}\")\n",
    "\tprint(f\"Validation loss {epoch + 1}, Loss: {val_loss / len(val_loader)}\")\n",
    "\n",
    "# Test\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "\tfor batch in test_loader:\n",
    "\t\tinput_ids = batch['input_ids'].to(device)\n",
    "\t\tlabels = batch['label'].to(device)\n",
    "\n",
    "\t\toutputs = model(input_ids)\n",
    "\t\t_, predicted = torch.max(outputs, 1)\n",
    "\t\ttotal += labels.size(0)\n",
    "\t\tcorrect += (predicted == labels).sum().item()\n",
    "\n",
    "# TODO: the quality of the model is not good at the moment\n",
    "# - log training and validation loss to understand the training process\n",
    "# - try out different learning rates, batch sizes, number of epochs, add early stopping\n",
    "print(f\"Test Accuracy: {correct / total:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1799abdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
